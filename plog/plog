#!/bin/bash
#NB "strict" mode is used if run as a script
SHA1SUM=9727578f8e158490091b3869cc5b442c50fbdc37
PLOG_VERSION=2018-11-14


version(){
    local sha=$(tail -n+4 $0 | sha1sum | cut -f1 -d' ')

    if [[ $SHA1SUM =~ $sha ]]; then
        echo "plog $PLOG_VERSION"
    else
        echo "plog $PLOG_VERSION (modified)"
    fi
}

FS_BASE="${FS_BASE:-/usr2}"
FS_PATH="${FS_PATH:-${FS_BASE}/fs}"
FS_LOG_PATH="${FS_LOG_PATH:-${FS_BASE}/log}"
FS_PROC_PATH="${FS_PROC_PATH:-${FS_BASE}/proc}"
FS_SCHED_PATH="${FS_SCHED_PATH:-${FS_BASE}/sched}"

# Lines to remove from log file to make "reduced" logs
# Use egrep syntax
PLOG_REDUCE_PATTERN="${PLOG_REDUCE_PATTERN:-^[:.0-9]*#rdtc}"

# Added to filename before extension of log files with all data
PLOG_FULL_SUFFIX="${PLOG_FULL_SUFFIX:-_full}"
# Check for compressed logs
PLOG_COMPRESSED_EXT="${PLOG_COMPRESSED_EXT:-gz}"

usage_long() {
    cat <<EOF
Push log files to the data centers.

USAGE:
    ${black}$0 [options] ARG [ARG...]${normal}

ARG can be an experiment ID or the path of a file.

${underline}Options:${normal}
    ${black}-l${normal}            Use latest log in $FS_LOG_PATH (other than 'station.log'
                  or 'point.log')
    ${black}-t${normal}            Test run: print commands, do not actually push files to server
    ${black}-h${normal}            Print this message
    ${black}-c CENTER${normal}     Push files to data CENTER. Overrides the DATA_CENTERS
                  environment variable. Flag can be given multiple times.
    ${black}-p${normal}            Also push proc file
    ${black}-q${normal}            Quiet mode
    ${black}-z${normal}            Push compressed log (full if contains multicast data)
    ${black}-v${normal}            Print plog version and exit

If the log containing RDBE multicast data:

1.  If not already done so, the log file will be renamed to
    '$FS_LOG_PATH/<log>_full.log'

2.  Unless '-z' is supplied, a reduced log file, without multicast data, is
    created in /tmp and this is transferred to the data center.

To see progress when compressing and reducing, install the 'pv' package.

plog requires the STATION environment variable be set to the lower case
two-letter station code in. E.g. add the following ~/.login (tcsh) or
~/.profile (bash):

    setenv STATION gs ${blue}#tcsh${normal}
    export STATION=gs ${blue}#bash${normal}

Data centers are specified in the DATA_CENTERS environment variable which can
contain CDDIS, OPAR, BKG, HAYSTACK (VGOS only). Multiple centers are separated
with a space. E.g. add the following to your login script

    setenv DATA_CENTERS "CDDIS HAYSTACK" ${blue}#tcsh${normal}
    export DATA_CENTERS="CDDIS HAYSTACK" ${blue}#bash${normal}

If DATA_CENTERS is empty, plog defaults to CDDIS.

Data center login must be configured in "~/.netrc".  For example, for CDDIS

    machine urs.earthdata.nasa.gov
        login mycddisuser
        password secret

See NETRC(5) for more details.

Examples of usage:
    ${blue}# push log for latest session, sending reduced if needed${normal}
    plog -l
    ${blue}# push log and proc files for session vgp007${normal}
    plog -p vgp007
    ${blue}# push (full) compressed log for vgp007${normal}
    plog -z vgp007
    ${blue}# push everything in /usr2/log to Haystack${normal}
    plog -c HAYSTACK /usr2/log/*.log

EOF
}

bold=
underline=
standout=
normal=
black=
red=
green=
yellow=
blue=
magenta=
cyan=
white=
# Check if stdout is a terminal
if test -t 1; then
    # see if it supports colors...
    ncolors=$(tput colors)
    if [[ -n "$ncolors" ]] && [[ $ncolors -ge 8 ]]; then
        bold="$(tput bold)"
        underline="$(tput smul)"
        standout="$(tput smso)"
        normal="$(tput sgr0)"
        black="$(tput setaf 0)"
        red="$(tput setaf 1)"
        green="$(tput setaf 2)"
        yellow="$(tput setaf 3)"
        blue="$(tput setaf 4)"
        magenta="$(tput setaf 5)"
        cyan="$(tput setaf 6)"
        white="$(tput setaf 7)"
    fi
fi


usage(){
    cat <<EOF
Usage: $0 [-l] [-t] [-h] [-c CENTER] ARG ...
Push log file(s) to the data centers.
EOF
}

fatal(){
    echo -e "${red}ERROR:${normal} plog:" "$*" >&2
    exit 1
}

warn(){
    if [[ -z "$QUIET" ]]; then
        echo -e "${yellow}WARN:${normal} plog:" "$@" >&2
    fi
}
info(){
    if [[ -z "$QUIET" ]]; then
        echo -e "${green}INFO:${normal} plog:" "$@" >&2
    fi
}

# Check if pv (Pipe Viewer) is installed.
# Used for progress meters

safe_pv() {
    PV=$(which pv)
    if [[ -n "$QUIET" || $? -ne 0 ]]; then
        cat $@
        return
    fi
    $PV $@
}

## Put Commands
# Helper functions for data center commands
# follow signatures
# f URL file [file...]
pftp() {
    if ! which curl > /dev/null; then
        fatal "'curl' not found"
    fi
    URL="$1"; shift
    local F=($@) #Turn into an array so IFS is used in expansion
    local IFS=","
    $DRY curl -n -T "{${F[*]}}" "ftp://$URL/"
}

pscp() {
    URL="$1"; shift
    $DRY scp $@ "$URL"
}
dummy() {
    echo $@
}

## Utility functions
# Format an array with first arg as template. Used for curl.
fmtarray() {
    local FMT="$1"; shift
    for f in $@; do
        printf "$FMT" "$f"
    done
}
# Add file to upload queue
add() {
    FILES+=($@)
    info queued $@
}

CDDIS_URL="https://depot.cddis.eosdis.nasa.gov/CDDIS_FileUpload"
cddis() {
    # Check if curl is installed.
    if ! which curl > /dev/null; then
        fatal "'curl' not found"
    fi

    if [[ ! -e "$HOME/.netrc" ]]; then
        fatal "$HOME/.netrc not found, see usage"
    fi

    if ! grep -q urs.earthdata.nasa.gov "$HOME/.netrc"; then
        fatal "$HOME/.netrc does not contain CDDIS login information, see usage"
    fi

    local DRY=${DRY:-" >/dev/null"}

    info "Logging into CDDIS..."
    # Curl flags used:
    # -c     -- cookie jar (write)
    # -b     -- cookie jar (read)
    # -n     -- use netrc file for logins
    # -f     -- set return flag to 22 on HTTP error
    # -F     -- form data
    # -k     -- insecure mode (required on older versions of Debian), should 
    #           be removed eventually
    # -s -S  -- silent except on errors
    
    # Disallow reading cookie file for other users
    local mask=$(umask)
    umask 0077

    eval $DRY curl\
        -c $HOME/.urs_cookies \
        -n \
        -k \
        -f -s -S \
        -L \
        $CDDIS_URL/login 

    info "Done"

    info "Copying file to CDDIS..."

    local quiet=""
    if [[ -z "$QUIET" ]]; then 
        local quiet="-s -S"
    fi


    eval $DRY curl -X POST \
        -b $HOME/.urs_cookies \
        -k \
        -f \
        $quiet \
        -F "fileType=VLBI" \
        $(fmtarray ' -F "file[]=@%s"' $@) \
        $CDDIS_URL/upload/
    info "Done"

    # Restore previous umask
    umask $mask
}

OPAR_URL="https://ivsopar.obspm.fr/upload/scripts/upload.php"
opar() {
    # Check if curl is installed.
    if ! which curl > /dev/null; then
        fatal "'curl' not found"
    fi

    if [[ ! -e "$HOME/.netrc" ]]; then
        fatal "$HOME/.netrc not found, see usage"
    fi

    if ! grep -q ivsopar.obspm.fr "$HOME/.netrc"; then
        fatal "$HOME/.netrc does not contain OPAR login information, see usage"
    fi

    local DRY=${DRY:-" >/dev/null"}

    info "Copying files to OPAR..."
    while (( "$#" )); do
        eval $DRY curl \
            -n \
            -k \
            -F "fichier=@$1" -F 'mode=upload' $OPAR_URL
        shift
    done
    info "Done"
}

## Commands for Data Centers
PLOG_CTR_CDDIS="cddis"
PLOG_CTR_OPAR="opar"
PLOG_CTR_BKG="pftp ivs.bkg.bund.de"
PLOG_CTR_HAYSTACK="pscp evlbi1.haystack.mit.edu:/data-st12/vgos/logs"
PLOG_CTR_DUMMY="dummy"

# Hack to work around older versions of bash not having asoc arrays
# gets all env variables that start with "PLOG_CTR_" and assume the rest of
# the name is the key.
CTRS=$(compgen -A variable | grep PLOG_CTR_ | cut -c $(echo "PLOG_CTR_" | wc -c)- | paste -s -d" ")


# Default Data center
DATA_CENTERS=${DATA_CENTERS:-"CDDIS"}


joinlst () {
    local IFS=" "
    echo "$*" | sed 's/ /, /g' | sed 's/, \(\S*\)$/ or \1/g'
}

opening_process_name() {
    local pid=$(fuser $1 2>/dev/null  | sed -e 's/^[[:space:]]*//' | head -n1)
    if [[ -z "$pid" ]]; then
        return
    fi
    ps -o comm= -p $pid
}

# Compress the log to a temp directory
# Do not compress already compressed files
compress() {
    if [[ ${1##*.} == $PLOG_COMPRESSED_EXT ]]; then
        echo "$1"
        return
    fi

    local ext=${1#*.}
    local name=$(basename "$1")
    local out="/tmp/$name.$PLOG_COMPRESSED_EXT"

    info Compressing log file...
    if [[ -n "$DRY" ]]; then
        >&2 echo "gzip --best -c $1 >  $out"
    else
        safe_pv "$1" | gzip --best > "$out"
    fi
    echo "$out"
}
# Uncompress the log to a temp directory
uncompress() {
    local name=$(basename $1 .$PLOG_COMPRESSED_EXT)
    local out="/tmp/$name"

    info Uncompressing log file...
    if [[ -n "$DRY" ]]; then
        >&2 echo "gunzip -c $1 >  $out"
    else
        safe_pv "$1" | gunzip > "$out"
    fi
    echo "$out"
}

# Return a reduced log in /tmp can either be raw or compressed log
reduce() {
    local ext=${1#*.}
    local name=$(basename $(basename "$1" .$ext) $PLOG_FULL_SUFFIX)
    local out="/tmp/$name.log"
    info Creating reduced log file...
    if [[ -n "$DRY" ]]; then
        >&2 echo "zegrep -v "$PLOG_REDUCE_PATTERN" $1 > $out"
    else
        safe_pv "$1" | zegrep -v "$PLOG_REDUCE_PATTERN" > "$out"
    fi
    echo "$out"
}

# Find latest modified log in $FS_LOG_PATH which isn't station or point
get_latest_exp() {
    local log=$(ls -t $FS_LOG_PATH\
        | grep "$STATION\($PLOG_FULL_SUFFIX\)\?\\.log\(.$PLOG_COMPRESSED_EXT\)\?\$"\
        | egrep -v '(station|point)'\
        | head -1)

    local ext=${log#*.}
    local expname
    expname=$(basename "$log" .$ext)
    expname=$(basename $expname $PLOG_FULL_SUFFIX)
    expname=$(basename $expname $STATION)
    echo $expname
}

main () {
    #STATION = Two letter station code, eg "gs"
    CENTERS_OVER=
    LATEST=
    DRY=
    PUSH_PROC=
    COMPRESS=
    QUIET=
    while getopts hltqpzvc: opt; do
        case $opt in
            l)
                LATEST=1
                ;;
            t)
                DRY=echo
                ;;
            c)
                if [[ ! $CTRS =~ $OPTARG ]]; then
                    fatal "Unknown data center '$OPTARG'"
                fi
                CENTERS_OVER="$CENTERS_OVER $OPTARG"
                ;;
            p)
                PUSH_PROC=1
                ;;
            q)
                QUIET=1
                ;;
            z)
                COMPRESS=1
                ;;
            h)
                usage_long
                exit
                ;;
            v) 
                version $0
                exit
                ;;
            *)
                usage >&2
                exit 1
                ;;
            :)
              fatal "Option -$OPTARG requires an argument."
              ;;
        esac
    done
    shift $(($OPTIND - 1))



    # Default DATA_CENTERS overridden by flag
    if [[ -n "$CENTERS_OVER" ]]; then
        DATA_CENTERS=$CENTERS_OVER
    fi

    for center in $DATA_CENTERS; do
        set +u
        if [[ -z  "$(eval echo \$PLOG_CTR_$center)" ]]; then
            fatal "unknown data center '$center'"
        fi
        set -u
    done

    # If LATEST not set and no arguments, exit
    if [[ -z "$LATEST" && "$#" -eq 0 ]]; then
        usage >&2
        exit 1
    fi

    # List of files or experiment names
    REFS=($@)
    # List of exisiting files that will be pushed
    FILES=()

    if [[ -n "$LATEST" ]]; then
        llog=$(get_latest_exp)
        REFS+=( $llog )
    fi

    for ref in ${REFS[@]}; do
        # First check if the argument looks like a path.
        # If does, check if it is a file.
        # If it's a file, do not process it, just add it to
        # the list; if it isn't, complain and exit.
        if [[ "$ref" =~ /  ]]; then
            if [[ -f "$ref" ]]; then
                add $ref
                continue
            else
                fatal "file $ref not found"
            fi
        fi

        # If it's not a file, assume it's the name of an observation.
        
        # we need the name of the station if we're going to lookup by observation name
        set +u
        if [[ -z "$STATION" ]]; then
            fatal "STATION environment variable not set. Set to lower case two-letter station id."
        fi
        set -u

        # Should we add the proc file?
        if [[ -n "$PUSH_PROC" ]]; then
            proc="$FS_PROC_PATH/$ref$STATION.prc"
            if [[ ! -f "$proc" ]]; then
                fatal "$proc not found"
            fi
            add $proc
        fi

        # Look for a regular log, a full log, or a compressed version of either.
        # If more than one exists, abort and ask the user to deal with it
        log=()
        for f in $FS_LOG_PATH/$ref${STATION}{,$PLOG_FULL_SUFFIX}.log{,.$PLOG_COMPRESSED_EXT}; do
            if [[ -f $f ]]; then
                info found $f
                log+=( $f )
            fi
        done
        if [[ ${#log[@]} -lt 1 ]]; then
            fatal "log file for $ref not found"
            exit
        fi
        if [[ ${#log[@]} -gt 1 ]]; then
            fatal "Conflicting log files:"\
                  "\n$(IFS=$'\n';echo -e "${log[*]}")\n"\
                  "Inspect the files and either concatenate them or removed the invalid one(s)."
        fi

        # If log contains multicast data, rename to _full.* since we will upload a reduced file
        FULL=
        if zegrep -q "$PLOG_REDUCE_PATTERN" $log; then
            FULL=1
            logext=${log#*.} # extension, preserving .gz if it exists
            full=$FS_LOG_PATH/$ref$STATION$PLOG_FULL_SUFFIX.$logext
            if [[ $log != $full ]]; then
                pname=$(opening_process_name $log)
                if [[ -n $pname ]]; then
                    fatal $log is open by $pname, aborting
                fi
                # This should be safe, because we checked if file exists earlier. Use "-n" just in case.
                warn file contains multicast, renaming $(basename $log) to $(basename $full)
                $DRY mv -n $log $full
            fi
            log=$full
        fi

        # If given '-z' command, compressed file, add it to the queue, and move on
        if [[ -n "$COMPRESS" ]]; then
            add $(compress $log)
            continue
        fi

        # If log doesn't contains data that should be excluded in reduced log, add it to queue and move on.
        if [[ -z "$FULL" ]]; then
            # If log is compressed, extract in a tmp dir upload
            if [[ $log =~ $PLOG_COMPRESSED_EXT$ ]]; then
                add $(uncompress $log)
                continue
            fi
            add $log
            continue
        fi

        # The log must now contain multicast data, and we haven't been told to upload
        # the full compressed file so generate reduced log and add it to the queue
        # To avoid a name conflict, this renames the file while preserving the extension.
        add $(reduce $log)
    done

    for center in $DATA_CENTERS; do
        info uploading to $center
        eval \$PLOG_CTR_$center ${FILES[@]}
    done
}

# Don't run main if file is being "source"d
# Useful for testing
if [[ $0 == "$BASH_SOURCE" ]]; then
    #'strict' mode
    # "-e" exits on error
    # "-u" error on undef variable
    # "-o pipefail" error if any command in a pipe fails
    set -euo pipefail
    main "$@"
fi
